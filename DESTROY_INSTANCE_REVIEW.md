# Destroy Instance Script Review

## Current Implementation

The `destroy-instance.sh` script deletes tenant data in two steps:

### Step 1: Delete Ingress Rule ‚úÖ
```bash
kubectl delete ingress "${INGRESS_NAME}" -n "${NAMESPACE}"
```
- **Works correctly**: Deletes Kubernetes ingress resource
- **No issues**: Standard Kubernetes operation

### Step 2: Delete Tenant Data Files ‚ö†Ô∏è

**Current approach:**
```bash
sudo -n rm -rf "$DATA_DIR" || echo "    ‚ö†Ô∏è  Failed to remove: $DATA_DIR"
sudo -n rm -rf "$ATTACHMENTS_DIR" || echo "    ‚ö†Ô∏è  Failed to remove: $ATTACHMENTS_DIR"
sudo -n rm -rf "$AVATARS_DIR" || echo "    ‚ö†Ô∏è  Failed to remove: $AVATARS_DIR"
```

**Paths being deleted:**
- `/data/nfs-server/data/tenants/${INSTANCE_NAME}`
- `/data/nfs-server/attachments/tenants/${INSTANCE_NAME}`
- `/data/nfs-server/avatars/tenants/${INSTANCE_NAME}`

## Architecture Context

### NFS Storage Structure

```
Host Node (k8s)
‚îî‚îÄ‚îÄ /data/nfs-server/                    (hostPath)
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îî‚îÄ‚îÄ tenants/
    ‚îÇ       ‚îú‚îÄ‚îÄ app/
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ kanban.db
    ‚îÇ       ‚îú‚îÄ‚îÄ fastest/
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ kanban.db
    ‚îÇ       ‚îî‚îÄ‚îÄ {tenant-id}/
    ‚îú‚îÄ‚îÄ attachments/
    ‚îÇ   ‚îî‚îÄ‚îÄ tenants/
    ‚îÇ       ‚îî‚îÄ‚îÄ {tenant-id}/
    ‚îî‚îÄ‚îÄ avatars/
        ‚îî‚îÄ‚îÄ tenants/
            ‚îî‚îÄ‚îÄ {tenant-id}/

NFS Server Pod
‚îî‚îÄ‚îÄ /exports/                            (mounted from hostPath)
    ‚îú‚îÄ‚îÄ data/                            (exported as NFS)
    ‚îÇ   ‚îî‚îÄ‚îÄ tenants/
    ‚îÇ       ‚îî‚îÄ‚îÄ {tenant-id}/
    ‚îú‚îÄ‚îÄ attachments/                      (exported as NFS)
    ‚îÇ   ‚îî‚îÄ‚îÄ tenants/
    ‚îÇ       ‚îî‚îÄ‚îÄ {tenant-id}/
    ‚îî‚îÄ‚îÄ avatars/                         (exported as NFS)
        ‚îî‚îÄ‚îÄ tenants/
            ‚îî‚îÄ‚îÄ {tenant-id}/

Easy Kanban Pods
‚îî‚îÄ‚îÄ /app/server/                         (mounted from NFS)
    ‚îú‚îÄ‚îÄ data/                            (maps to /exports/data)
    ‚îÇ   ‚îî‚îÄ‚îÄ tenants/
    ‚îÇ       ‚îî‚îÄ‚îÄ {tenant-id}/
    ‚îú‚îÄ‚îÄ attachments/                     (maps to /exports/attachments)
    ‚îÇ   ‚îî‚îÄ‚îÄ tenants/
    ‚îÇ       ‚îî‚îÄ‚îÄ {tenant-id}/
    ‚îî‚îÄ‚îÄ avatars/                         (maps to /exports/avatars)
        ‚îî‚îÄ‚îÄ tenants/
            ‚îî‚îÄ‚îÄ {tenant-id}/
```

## Issues with Current Implementation

### Issue 1: Requires Passwordless Sudo ‚ùå
- **Problem**: `sudo -n` requires passwordless sudo configuration
- **Impact**: Script fails if sudo requires password
- **Error**: `sudo: a password is required`

### Issue 2: Must Run on NFS Server Node ‚ùå
- **Problem**: Script assumes it's running on the node where NFS server pod runs
- **Impact**: Won't work if run from:
  - Different node
  - Admin portal (different machine)
  - CI/CD pipeline
- **Error**: Directories not found (if on wrong node)

### Issue 3: No Verification ‚ùå
- **Problem**: Uses `|| echo "‚ö†Ô∏è Failed"` which silently continues
- **Impact**: Script reports success even if deletion fails
- **Risk**: Data not actually deleted, but ingress is removed

### Issue 4: Race Condition ‚ö†Ô∏è
- **Problem**: Files might be in use by running pods
- **Impact**: Deletion might fail or cause issues
- **Risk**: Database corruption if deleted while in use

## Better Approaches

### Option 1: Delete via NFS Server Pod ‚úÖ (Recommended)

Delete files through the NFS server pod using `kubectl exec`:

```bash
# Get NFS server pod
NFS_POD=$(kubectl get pod -n easy-kanban -l app=nfs-server -o jsonpath='{.items[0].metadata.name}')

# Delete tenant directories via pod
kubectl exec -n easy-kanban "$NFS_POD" -- sh -c "
  rm -rf /exports/data/tenants/${INSTANCE_NAME} && \
  rm -rf /exports/attachments/tenants/${INSTANCE_NAME} && \
  rm -rf /exports/avatars/tenants/${INSTANCE_NAME}
"
```

**Advantages:**
- ‚úÖ Works from anywhere (doesn't need to be on NFS node)
- ‚úÖ No sudo required
- ‚úÖ Works in Kubernetes context
- ‚úÖ Can verify deletion

**Disadvantages:**
- ‚ö†Ô∏è Requires NFS server pod to be running
- ‚ö†Ô∏è Requires kubectl access

### Option 2: Delete via Easy Kanban Pod ‚úÖ

Delete files through an Easy Kanban pod that has the volumes mounted:

```bash
# Get an Easy Kanban pod
APP_POD=$(kubectl get pod -n easy-kanban -l app=easy-kanban -o jsonpath='{.items[0].metadata.name}')

# Delete tenant directories via pod
kubectl exec -n easy-kanban "$APP_POD" -- sh -c "
  rm -rf /app/server/data/tenants/${INSTANCE_NAME} && \
  rm -rf /app/server/attachments/tenants/${INSTANCE_NAME} && \
  rm -rf /app/server/avatars/tenants/${INSTANCE_NAME}
"
```

**Advantages:**
- ‚úÖ Works from anywhere
- ‚úÖ No sudo required
- ‚úÖ Uses mounted volumes (same as app sees them)

**Disadvantages:**
- ‚ö†Ô∏è Requires Easy Kanban pod to be running
- ‚ö†Ô∏è Files might be in use (database open)

### Option 3: Use Kubernetes Job ‚úÖ (Most Robust)

Create a Kubernetes Job to delete the files:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: delete-tenant-${INSTANCE_NAME}
  namespace: easy-kanban
spec:
  template:
    spec:
      containers:
      - name: cleanup
        image: busybox:latest
        command: ['sh', '-c']
        args:
        - |
          rm -rf /data/tenants/${INSTANCE_NAME} && \
          rm -rf /attachments/tenants/${INSTANCE_NAME} && \
          rm -rf /avatars/tenants/${INSTANCE_NAME}
        volumeMounts:
        - name: data
          mountPath: /data
        - name: attachments
          mountPath: /attachments
        - name: avatars
          mountPath: /avatars
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: easy-kanban-shared-pvc-data
      - name: attachments
        persistentVolumeClaim:
          claimName: easy-kanban-shared-pvc-attachments
      - name: avatars
        persistentVolumeClaim:
          claimName: easy-kanban-shared-pvc-avatars
      restartPolicy: Never
```

**Advantages:**
- ‚úÖ Most robust (handles failures, retries)
- ‚úÖ Can verify completion
- ‚úÖ Works from anywhere
- ‚úÖ No sudo required

**Disadvantages:**
- ‚ö†Ô∏è More complex (requires creating Job manifest)
- ‚ö†Ô∏è Need to clean up Job after completion

## Recommended Solution

**Use Option 1 (Delete via NFS Server Pod)** because:
1. ‚úÖ Simple and straightforward
2. ‚úÖ Works from anywhere with kubectl access
3. ‚úÖ No sudo required
4. ‚úÖ Direct access to source of truth (NFS server)

### Improved Script

```bash
# Step 2: Remove tenant data directories from NFS
echo "üóëÔ∏è  Removing tenant data directories from NFS..."

# Get NFS server pod
NFS_POD=$(kubectl get pod -n "${NAMESPACE}" -l app=nfs-server -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)

if [ -z "$NFS_POD" ]; then
    echo "   ‚ö†Ô∏è  NFS server pod not found, trying direct host path deletion..."
    # Fallback to original method
    if [ -d "$DATA_DIR" ]; then
        sudo -n rm -rf "$DATA_DIR" || echo "    ‚ö†Ô∏è  Failed to remove: $DATA_DIR"
    fi
    if [ -d "$ATTACHMENTS_DIR" ]; then
        sudo -n rm -rf "$ATTACHMENTS_DIR" || echo "    ‚ö†Ô∏è  Failed to remove: $ATTACHMENTS_DIR"
    fi
    if [ -d "$AVATARS_DIR" ]; then
        sudo -n rm -rf "$AVATARS_DIR" || echo "    ‚ö†Ô∏è  Failed to remove: $AVATARS_DIR"
    fi
else
    echo "   Using NFS server pod: $NFS_POD"
    
    # Delete via NFS server pod
    kubectl exec -n "${NAMESPACE}" "$NFS_POD" -- sh -c "
        if [ -d /exports/data/tenants/${INSTANCE_NAME} ]; then
            rm -rf /exports/data/tenants/${INSTANCE_NAME} && echo '  ‚úÖ Deleted: /exports/data/tenants/${INSTANCE_NAME}'
        else
            echo '  ‚ÑπÔ∏è  Directory not found: /exports/data/tenants/${INSTANCE_NAME}'
        fi
    " || echo "    ‚ö†Ô∏è  Failed to delete data directory"
    
    kubectl exec -n "${NAMESPACE}" "$NFS_POD" -- sh -c "
        if [ -d /exports/attachments/tenants/${INSTANCE_NAME} ]; then
            rm -rf /exports/attachments/tenants/${INSTANCE_NAME} && echo '  ‚úÖ Deleted: /exports/attachments/tenants/${INSTANCE_NAME}'
        else
            echo '  ‚ÑπÔ∏è  Directory not found: /exports/attachments/tenants/${INSTANCE_NAME}'
        fi
    " || echo "    ‚ö†Ô∏è  Failed to delete attachments directory"
    
    kubectl exec -n "${NAMESPACE}" "$NFS_POD" -- sh -c "
        if [ -d /exports/avatars/tenants/${INSTANCE_NAME} ]; then
            rm -rf /exports/avatars/tenants/${INSTANCE_NAME} && echo '  ‚úÖ Deleted: /exports/avatars/tenants/${INSTANCE_NAME}'
        else
            echo '  ‚ÑπÔ∏è  Directory not found: /exports/avatars/tenants/${INSTANCE_NAME}'
        fi
    " || echo "    ‚ö†Ô∏è  Failed to delete avatars directory"
fi
```

## Additional Considerations

### Database Connection Cleanup

Before deleting, consider:
1. **Close database connections**: The SQLite proxy might have open connections
2. **Wait for operations**: Ensure no active queries
3. **Backup option**: Offer backup before deletion

### Verification

Add verification after deletion:
```bash
# Verify deletion
kubectl exec -n "${NAMESPACE}" "$NFS_POD" -- sh -c "
    [ ! -d /exports/data/tenants/${INSTANCE_NAME} ] && \
    [ ! -d /exports/attachments/tenants/${INSTANCE_NAME} ] && \
    [ ! -d /exports/avatars/tenants/${INSTANCE_NAME} ] && \
    echo '‚úÖ All tenant directories deleted successfully' || \
    echo '‚ö†Ô∏è  Some directories still exist'
"
```

## Summary

**Current Issues:**
- ‚ùå Requires passwordless sudo
- ‚ùå Must run on NFS server node
- ‚ùå No proper error handling
- ‚ùå No verification

**Recommended Fix:**
- ‚úÖ Use `kubectl exec` to delete via NFS server pod
- ‚úÖ Works from anywhere with kubectl access
- ‚úÖ No sudo required
- ‚úÖ Add verification step
- ‚úÖ Fallback to host path if NFS pod unavailable

